{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTiB E2024 - Week 12 - Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theoretical exercises\n",
    "\n",
    "***Exercise 1***: How many terms are there in the sum on slide 13 from the lecture on Nov 18 for computing $P({\\bf X}|\\Theta)$? Why?\n",
    "\n",
    "***Exercise 2***: How many terms are there in the maximization on slide 68 in the Viterbi decoding slides from the lecure on Nov 18 for computing the Viterbi decoding ${\\bf Z}^*$? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical exercises\n",
    "\n",
    "You are given the same 7-state HMM and helper functions that you used last week:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:44.480685Z",
     "start_time": "2024-12-01T13:33:44.475658Z"
    }
   },
   "source": [
    "from prompt_toolkit.key_binding.bindings.named_commands import kill_word\n",
    "\n",
    "\n",
    "class hmm:\n",
    "    def __init__(self, init_probs, trans_probs, emission_probs):\n",
    "        self.init_probs = init_probs\n",
    "        self.trans_probs = trans_probs\n",
    "        self.emission_probs = emission_probs"
   ],
   "outputs": [],
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:44.530887Z",
     "start_time": "2024-12-01T13:33:44.525210Z"
    }
   },
   "source": [
    "init_probs_7_state = [0.00, 0.00, 0.00, 1.00, 0.00, 0.00, 0.00]\n",
    "\n",
    "trans_probs_7_state = [\n",
    "    [0.00, 0.00, 0.90, 0.10, 0.00, 0.00, 0.00],\n",
    "    [1.00, 0.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    [0.00, 1.00, 0.00, 0.00, 0.00, 0.00, 0.00],\n",
    "    [0.00, 0.00, 0.05, 0.90, 0.05, 0.00, 0.00],\n",
    "    [0.00, 0.00, 0.00, 0.00, 0.00, 1.00, 0.00],\n",
    "    [0.00, 0.00, 0.00, 0.00, 0.00, 0.00, 1.00],\n",
    "    [0.00, 0.00, 0.00, 0.10, 0.90, 0.00, 0.00],\n",
    "]\n",
    "\n",
    "emission_probs_7_state = [\n",
    "    #   A     C     G     T\n",
    "    [0.30, 0.25, 0.25, 0.20],\n",
    "    [0.20, 0.35, 0.15, 0.30],\n",
    "    [0.40, 0.15, 0.20, 0.25],\n",
    "    [0.25, 0.25, 0.25, 0.25],\n",
    "    [0.20, 0.40, 0.30, 0.10],\n",
    "    [0.30, 0.20, 0.30, 0.20],\n",
    "    [0.15, 0.30, 0.20, 0.35],\n",
    "]\n",
    "\n",
    "hmm_7_state = hmm(init_probs_7_state, trans_probs_7_state, emission_probs_7_state)"
   ],
   "outputs": [],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:44.584551Z",
     "start_time": "2024-12-01T13:33:44.577914Z"
    }
   },
   "source": [
    "def translate_observations_to_indices(obs):\n",
    "    mapping = {'a': 0, 'c': 1, 'g': 2, 't': 3}\n",
    "    return [mapping[symbol.lower()] for symbol in obs]\n",
    "\n",
    "def translate_indices_to_observations(indices):\n",
    "    mapping = ['a', 'c', 'g', 't']\n",
    "    return ''.join(mapping[idx] for idx in indices)\n",
    "\n",
    "def translate_path_to_indices(path):\n",
    "    return list(map(lambda x: int(x), path))\n",
    "\n",
    "def translate_indices_to_path(indices):\n",
    "    return ''.join([str(i) for i in indices])"
   ],
   "outputs": [],
   "execution_count": 90
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1 - Viterbi Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you will implement and experiment with the Viterbi algorithm. The implementation has been split into three parts:\n",
    "\n",
    "1. Fill out the $\\omega$ table using the recursion presented at the lecture.\n",
    "2. Find the state with the highest probability after observing the entire sequence of observations.\n",
    "3. Backtrack from the state found in the previous step to obtain the optimal path.\n",
    "\n",
    "We'll be working with the 7-state model (`hmm_7_state`) and the helper function for translating between observations, hidden states, and indicies, as introduced above (and also used last week)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, you're given the function below that constructs a table of a specific size filled with zeros."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:44.646829Z",
     "start_time": "2024-12-01T13:33:44.641035Z"
    }
   },
   "source": [
    "def make_table(m, n):\n",
    "    \"\"\"Make a table with `m` rows and `n` columns filled with zeros.\"\"\"\n",
    "    return [[0] * n for _ in range(m)]"
   ],
   "outputs": [],
   "execution_count": 91
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll be testing your code with the same two sequences as last week, i.e:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:44.700124Z",
     "start_time": "2024-12-01T13:33:44.694987Z"
    }
   },
   "source": [
    "x_short = 'GTTTCCCAGTGTATATCGAGGGATACTACGTGCATAGTAACATCGGCCAA'\n",
    "z_short = '33333333333321021021021021021021021021021021021021'"
   ],
   "outputs": [],
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:44.767624Z",
     "start_time": "2024-12-01T13:33:44.757378Z"
    }
   },
   "source": [
    "x_long = 'TGAGTATCACTTAGGTCTATGTCTAGTCGTCTTTCGTAATGTTTGGTCTTGTCACCAGTTATCCTATGGCGCTCCGAGTCTGGTTCTCGAAATAAGCATCCCCGCCCAAGTCATGCACCCGTTTGTGTTCTTCGCCGACTTGAGCGACTTAATGAGGATGCCACTCGTCACCATCTTGAACATGCCACCAACGAGGTTGCCGCCGTCCATTATAACTACAACCTAGACAATTTTCGCTTTAGGTCCATTCACTAGGCCGAAATCCGCTGGAGTAAGCACAAAGCTCGTATAGGCAAAACCGACTCCATGAGTCTGCCTCCCGACCATTCCCATCAAAATACGCTATCAATACTAAAAAAATGACGGTTCAGCCTCACCCGGATGCTCGAGACAGCACACGGACATGATAGCGAACGTGACCAGTGTAGTGGCCCAGGGGAACCGCCGCGCCATTTTGTTCATGGCCCCGCTGCCGAATATTTCGATCCCAGCTAGAGTAATGACCTGTAGCTTAAACCCACTTTTGGCCCAAACTAGAGCAACAATCGGAATGGCTGAAGTGAATGCCGGCATGCCCTCAGCTCTAAGCGCCTCGATCGCAGTAATGACCGTCTTAACATTAGCTCTCAACGCTATGCAGTGGCTTTGGTGTCGCTTACTACCAGTTCCGAACGTCTCGGGGGTCTTGATGCAGCGCACCACGATGCCAAGCCACGCTGAATCGGGCAGCCAGCAGGATCGTTACAGTCGAGCCCACGGCAATGCGAGCCGTCACGTTGCCGAATATGCACTGCGGGACTACGGACGCAGGGCCGCCAACCATCTGGTTGACGATAGCCAAACACGGTCCAGAGGTGCCCCATCTCGGTTATTTGGATCGTAATTTTTGTGAAGAACACTGCAAACGCAAGTGGCTTTCCAGACTTTACGACTATGTGCCATCATTTAAGGCTACGACCCGGCTTTTAAGACCCCCACCACTAAATAGAGGTACATCTGA'\n",
    "z_long = '3333321021021021021021021021021021021021021021021021021021021021021021033333333334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210321021021021021021021021033334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563333333456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456332102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102103210210210210210210210210210210210210210210210210210210210210210'"
   ],
   "outputs": [],
   "execution_count": 93
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember to translate these sequences to indices before using them with your algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing without log-transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will implement the algorithm without log-transformation. This will cause issues with numerical stability (like above when computing the joint probability), so we will use the log-transformation trick to fix this in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the $\\omega$ table"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:44.830360Z",
     "start_time": "2024-12-01T13:33:44.825169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ViterbiResult:\n",
    "    def __init__(self, w, back_pointer):\n",
    "        self.w = w\n",
    "        self.back_pointer = back_pointer"
   ],
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:44.884791Z",
     "start_time": "2024-12-01T13:33:44.875108Z"
    }
   },
   "source": [
    "def compute_w(model, x):\n",
    "    k = len(model.init_probs)\n",
    "    n = len(x)\n",
    "    x = translate_observations_to_indices(x)\n",
    "    \n",
    "    # Step 1: Initialize the w and backpointer table\n",
    "    w = make_table(k, n)\n",
    "    back_pointer = make_table(k, n)  # Backpointer to reconstruct the path\n",
    "\n",
    "    # Initialize base cases (t=0)\n",
    "    for state in range(k):\n",
    "        w[state][0] = (\n",
    "            model.init_probs[state] * model.emission_probs[state][x[0]]\n",
    "        )\n",
    "        back_pointer[state][0] = None\n",
    "\n",
    "    # Step 2: Fill the w table for t > 0\n",
    "    for t in range(1, n):\n",
    "        for state in range(k):\n",
    "            max_prob, prev_state = max(\n",
    "                (\n",
    "                    w[prev_state][t-1] * model.trans_probs[prev_state][state],\n",
    "                    prev_state\n",
    "                )\n",
    "                for prev_state in range(k)\n",
    "            )\n",
    "            w[state][t] = max_prob * model.emission_probs[state][x[t]]\n",
    "            back_pointer[state][t] = prev_state\n",
    "    \n",
    "    return ViterbiResult(w, back_pointer)\n"
   ],
   "outputs": [],
   "execution_count": 95
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the joint probability of an optimal path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, write a function that given the $\\omega$-table, returns the probability of an optimal path through the HMM. As explained in the lecture, this corresponds to finding the highest probability in the last column of the table."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:44.938625Z",
     "start_time": "2024-12-01T13:33:44.931825Z"
    }
   },
   "source": [
    "def opt_path_prob(viterbi_res):\n",
    "    # Find the maximum value in the last column\n",
    "    last_column = [row[-1] for row in viterbi_res.w]  # Extract the last column\n",
    "    return max(last_column)  # Find the maximum value\n",
    "    \n",
    "#function for returning the index of the maximum probability in the last column\n",
    "def opt_path_prob_index(viterbi_res):\n",
    "    return max(enumerate(viterbi_res.w),key=lambda x: x[1][-1])[0]   "
   ],
   "outputs": [],
   "execution_count": 96
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Now test your implementation in the box below:"
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:44.993633Z",
     "start_time": "2024-12-01T13:33:44.986739Z"
    }
   },
   "source": [
    "result = compute_w(hmm_7_state, x_short)\n",
    "opt_path_prob(result)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9114255184318858e-31"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 97
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for `x_long`. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.089315Z",
     "start_time": "2024-12-01T13:33:45.055903Z"
    }
   },
   "source": [
    "result = compute_w(hmm_7_state, x_long)\n",
    "opt_path_prob(result)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining an optimal path through backtracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement backtracking to find a most probable path of hidden states given the $\\omega$-table."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.131220Z",
     "start_time": "2024-12-01T13:33:45.126975Z"
    }
   },
   "source": [
    "import math # REMEMBER TO USE math.isclose(a, b) when comparing floats!"
   ],
   "outputs": [],
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.186072Z",
     "start_time": "2024-12-01T13:33:45.181085Z"
    }
   },
   "source": [
    "def backtrack(model, x, viterbi_res):\n",
    "    n = len(x)\n",
    "    max_prob_index = opt_path_prob_index(viterbi_res)\n",
    "    path = [max_prob_index]\n",
    "    for t in range(n - 1, 0, -1):\n",
    "        path.insert(0, viterbi_res.back_pointer[path[0]][t]) \n",
    "    return path"
   ],
   "outputs": [],
   "execution_count": 100
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.242678Z",
     "start_time": "2024-12-01T13:33:45.231960Z"
    }
   },
   "source": [
    "viterbi_result = compute_w(hmm_7_state, x_short)\n",
    "z_viterbi = backtrack(hmm_7_state, x_short, viterbi_result)\n",
    "translate_indices_to_path(z_viterbi)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33333333333321021021021021021021021021021021021021'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 101
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for `x_long`. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.328603Z",
     "start_time": "2024-12-01T13:33:45.299757Z"
    }
   },
   "source": [
    "viterbi_result = compute_w(hmm_7_state, x_long)\n",
    "z_viterbi = backtrack(hmm_7_state, x_long, viterbi_result)\n",
    "translate_indices_to_path(z_viterbi)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3333321021021021021021021021021021021021021021021021021021021021021021033333333334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210321021021021021021021021033334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564566666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666666660'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 102
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.389672Z",
     "start_time": "2024-12-01T13:33:45.383355Z"
    }
   },
   "source": [
    "import math\n",
    "\n",
    "def log(x):\n",
    "    if x == 0:\n",
    "        return float('-inf')\n",
    "    return math.log(x)"
   ],
   "outputs": [],
   "execution_count": 103
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing with log-transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now implement the Viterbi algorithm with log-transformation. The steps are the same as above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation of the (log-transformed) $\\omega$ table"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.449862Z",
     "start_time": "2024-12-01T13:33:45.440644Z"
    }
   },
   "source": [
    "def compute_w_log(model, x):\n",
    "    k = len(model.init_probs)\n",
    "    n = len(x)\n",
    "    x = translate_observations_to_indices(x)\n",
    "    w = make_table(k, n)\n",
    "    \n",
    "    # Step 1: Initialize the w and backpointer table\n",
    "    back_pointer = make_table(k, n)  # Backpointer to reconstruct the path\n",
    "\n",
    "    # Initialize base cases (t=0)\n",
    "    for state in range(k):\n",
    "        w[state][0] = (\n",
    "            log(model.init_probs[state]) + log(model.emission_probs[state][x[0]])\n",
    "        )\n",
    "        back_pointer[state][0] = None\n",
    "\n",
    "    # Step 2: Fill the w table for t > 0\n",
    "    for t in range(1, n):\n",
    "        for state in range(k):\n",
    "            max_prob, prev_state = max(\n",
    "                (\n",
    "                    w[prev_state][t-1] + log(model.trans_probs[prev_state][state]),\n",
    "                    prev_state\n",
    "                )\n",
    "                for prev_state in range(k)\n",
    "            )\n",
    "            w[state][t] = max_prob + log(model.emission_probs[state][x[t]])\n",
    "            back_pointer[state][t] = prev_state\n",
    "    \n",
    "    return ViterbiResult(w, back_pointer)\n"
   ],
   "outputs": [],
   "execution_count": 104
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the (log-transformed) joint probability of an optimal path"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.498837Z",
     "start_time": "2024-12-01T13:33:45.495095Z"
    }
   },
   "source": [
    "#function for finding the optimal probability is essentially the same\n",
    "def opt_path_prob_log(viterbi_res):\n",
    "    return opt_path_prob(viterbi_res)"
   ],
   "outputs": [],
   "execution_count": 105
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.558060Z",
     "start_time": "2024-12-01T13:33:45.547445Z"
    }
   },
   "source": [
    "viterbi_result = compute_w_log(hmm_7_state, x_short)\n",
    "opt_path_prob_log(viterbi_result)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-70.73228857440488"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 106
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for `x_long`. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.658452Z",
     "start_time": "2024-12-01T13:33:45.612931Z"
    }
   },
   "source": [
    "viterbi_result = compute_w_log(hmm_7_state, x_long)\n",
    "opt_path_prob_log(viterbi_result)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1406.7209253880144"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 107
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining an optimal path through backtracking"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.719723Z",
     "start_time": "2024-12-01T13:33:45.713060Z"
    }
   },
   "source": [
    "#function for finding the optimal path is essentially the same\n",
    "def backtrack_log(model, x, viterbi_res):\n",
    "    return backtrack(model, x, viterbi_res)"
   ],
   "outputs": [],
   "execution_count": 108
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.793412Z",
     "start_time": "2024-12-01T13:33:45.775075Z"
    }
   },
   "source": [
    "viterbi_result = compute_w_log(hmm_7_state, x_short)\n",
    "z_viterbi_log = backtrack_log(hmm_7_state, x_short, viterbi_result)\n",
    "translate_indices_to_path(z_viterbi_log)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'33333333333321021021021021021021021021021021021021'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 109
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for `x_long`. What happens?"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:45.914686Z",
     "start_time": "2024-12-01T13:33:45.874146Z"
    }
   },
   "source": [
    "viterbi_result = compute_w_log(hmm_7_state, x_long)\n",
    "z_viterbi_long_log = backtrack_log(hmm_7_state, x_long, viterbi_result)\n",
    "translate_indices_to_path(z_viterbi_long_log)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3333321021021021021021021021021021021021021021021021021021021021021021033333333334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210210321021021021021021021021033334564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564564563333333456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456456332102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102102103210210210210210210210210210210210210210210210210210210210210210'"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 110
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does it work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think about how to verify that your implementations of Viterbi (i.e. `compute_w`, `opt_path_prob`, `backtrack`, and there log-transformed variants `compute_w_log`, `opt_path_prob_log`, `backtrack_log`) are correct.\n",
    "\n",
    "One thing that should hold is that the probability of a most likely path as computed by `opt_path_prob` (or `opt_path_prob_log`) for a given sequence of observables (e.g. `x_short` or `x_long`) should be equal to the joint probability of a corersponding most probable path as found by `backtrack` (or `backtrack_log`) and the given sequence of observables. Why?\n",
    "\n",
    "Make an experiment that validates that this is the case for your implementations of Viterbi and `x_short` and `x_long`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:34:00.476528Z",
     "start_time": "2024-12-01T13:34:00.393Z"
    }
   },
   "source": [
    "# To access joint_prob and joint_prob_log, you must copy your implementations from last week here ...\n",
    "\n",
    "def joint_prob(model, x, z):\n",
    "    x = translate_observations_to_indices(x)\n",
    "    # z = translate_path_to_indices(z)\n",
    "    \n",
    "    result = model.init_probs[z[0]] * model.emission_probs[z[0]][x[0]]\n",
    "    \n",
    "    for i in range(1, len(z)):\n",
    "        prev_state = z[i - 1]\n",
    "        state = z[i]\n",
    "        x_state = x[i]\n",
    "\n",
    "        result *= model.trans_probs[prev_state][state] * model.emission_probs[state][x_state]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def joint_prob_log(model, x, z):\n",
    "    x = translate_observations_to_indices(x)\n",
    "    # z = translate_path_to_indices(z)\n",
    "    \n",
    "    result = log(model.init_probs[z[0]]) + log(model.emission_probs[z[0]][x[0]])\n",
    "\n",
    "    for i in range(1, len(z)):\n",
    "        prev_state = z[i - 1]\n",
    "        state = z[i]\n",
    "        x_state = x[i]\n",
    "        \n",
    "        result += log(model.trans_probs[prev_state][state]) + log(model.emission_probs[state][x_state])\n",
    "\n",
    "    return result\n",
    "\n",
    "viterbi_result = compute_w(hmm_7_state, x_short)\n",
    "z_viterbi = backtrack(hmm_7_state, x_short, viterbi_result)\n",
    "\n",
    "# Check that opt_path_prob is equal to joint_prob(hmm_7_state, x_short, z_viterbi)\n",
    "print(\"opt_path_prob is equal to joint_prob(hmm_7_state, x_short, z_viterbi) :\")\n",
    "print( math.isclose(opt_path_prob(viterbi_result),joint_prob(hmm_7_state, x_short, z_viterbi)))\n",
    "\n",
    "viterbi_result = compute_w_log(hmm_7_state, x_short)\n",
    "z_viterbi_log = backtrack(hmm_7_state, x_short, viterbi_result)\n",
    "\n",
    "# Check that opt_path_prob_log is equal to joint_prob_log(hmm_7_state, x_short, z_viterbi_log)\n",
    "\n",
    "print(\"opt_path_prob_log is equal to joint_prob_log(hmm_7_state, x_short, z_viterbi_log) :\")\n",
    "print(math.isclose(opt_path_prob_log(viterbi_result),joint_prob_log(hmm_7_state, x_short, z_viterbi_log)))\n",
    "    \n",
    "# Do the above checks for x_long ...\n",
    "\n",
    "# Check that opt_path_prob is equal to joint_prob(hmm_7_state, x_long, z_viterbi)\n",
    "viterbi_result = compute_w(hmm_7_state, x_long)\n",
    "z_viterbi_long = backtrack(hmm_7_state, x_long, viterbi_result)\n",
    "\n",
    "print(\"opt_path_prob is equal to joint_prob(hmm_7_state, x_long, z_viterbi) :\")\n",
    "print(math.isclose(opt_path_prob(viterbi_result),joint_prob(hmm_7_state, x_long, z_viterbi_long)))\n",
    "\n",
    "viterbi_result = compute_w_log(hmm_7_state, x_long)\n",
    "z_viterbi_long_log = backtrack_log(hmm_7_state, x_long, viterbi_result)\n",
    "\n",
    "print(\"opt_path_prob is equal to joint_prob(hmm_7_state, x_long, z_viterbi) :\")\n",
    "print(math.isclose(opt_path_prob_log(viterbi_result),joint_prob_log(hmm_7_state, x_long, z_viterbi_long_log)))\n",
    "    "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_path_prob is equal to joint_prob(hmm_7_state, x_short, z_viterbi) :\n",
      "True\n",
      "opt_path_prob_log is equal to joint_prob_log(hmm_7_state, x_short, z_viterbi_log) :\n",
      "True\n",
      "opt_path_prob is equal to joint_prob(hmm_7_state, x_long, z_viterbi) :\n",
      "True\n",
      "opt_path_prob is equal to joint_prob(hmm_7_state, x_long, z_viterbi) :\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 113
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do your implementations pass the above checks?\n",
    "\n",
    "Yes, but only because the third print statement ends up comparing 0 and 0. So even though it passes, it compares two wrong values (which both happen to be 0, since the probabilities have become so small)..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does log-transformation matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an experiment that investigates how long the input string can be before `backtrack` and `backtrack_log` start to disagree on a most likely path and its probability."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-01T13:33:47.076936Z",
     "start_time": "2024-12-01T13:33:46.099725Z"
    }
   },
   "source": [
    "for i in range(10, len(x_long), 10):\n",
    "    x = x_long[:i]\n",
    "    z = z_long[:i]\n",
    "    \n",
    "    x_trans = translate_observations_to_indices(x)\n",
    "    z_trans = translate_path_to_indices(z)\n",
    "    viterbi_result = compute_w(hmm_7_state, x)\n",
    "    viterbi_result_log = compute_w_log(hmm_7_state, x)\n",
    "\n",
    "    no_log = backtrack(hmm_7_state, x, viterbi_result)\n",
    "    with_log = backtrack_log(hmm_7_state, x, viterbi_result_log)\n",
    "    if not no_log == with_log:\n",
    "        print(i)\n",
    "        break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "530\n"
     ]
    }
   ],
   "execution_count": 112
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer here:**\n",
    "\n",
    "For the 7-state model, `backtrack` and `backtrack_log` start to disagree on a most likely path and its probability for **i = 530** ."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
